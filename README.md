# Open Insurance Agent

### Um agente de IA modular e auditÃ¡vel para anÃ¡lise normativa do Open Insurance Brasil

---

## VisÃ£o Geral

O Open Insurance Agent Ã© um projeto de pesquisa aplicada desenvolvido por Luciano Coelho, doutorando em CiÃªncia da ComputaÃ§Ã£o pela UFSC, vinculado ao LaboratÃ³rio de SeguranÃ§a em ComputaÃ§Ã£o (LabSEC), sob orientaÃ§Ã£o do Prof. Ricardo CustÃ³dio.

A soluÃ§Ã£o combina tÃ©cnicas de RAG (Retrieval-Augmented Generation) e embeddings regulatÃ³rios com modelos de linguagem auditÃ¡veis, oferecendo um protÃ³tipo inovador para anÃ¡lise automatizada e segura de normas do Open Insurance Brasil. Essa abordagem permite rastreabilidade das fontes, auditoria das respostas e avaliaÃ§Ã£o contÃ­nua de mÃ©tricas de precisÃ£o e aderÃªncia normativa, garantindo maior confiabilidade nas interpretaÃ§Ãµes automatizadas de documentos oficiais.

A iniciativa integra esforÃ§os de inovaÃ§Ã£o regulatÃ³ria, inteligÃªncia artificial e ciberseguranÃ§a no contexto do Open Insurance Brasil (OPIN) â€” programa supervisionado pela SuperintendÃªncia de Seguros Privados (SUSEP) e vinculado ao ecossistema Open Finance Brasil.

**O projeto propÃµe um agente inteligente especializado em normas, diretrizes e padrÃµes tÃ©cnicos do Open Insurance, capaz de:**

- interpretar documentos oficiais da SUSEP, CNSP e CMN;

- responder a consultas tÃ©cnicas e regulatÃ³rias de forma fundamentada;

- gerar anÃ¡lises rastreÃ¡veis, explicÃ¡veis e auditÃ¡veis.  

---

## Arquitetura do Sistema

O sistema Ã© baseado em uma **arquitetura RAG (Retrieval-Augmented Generation)**, permitindo que as respostas da IA sejam sempre **fundamentadas em documentos oficiais**.  
O fluxo completo Ã© dividido em cinco camadas:

```bash
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User Interface                     â”‚
â”‚     (CLI, API REST ou Chat Interface)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                        RAG Layer                      â”‚
â”‚  â€¢ RecuperaÃ§Ã£o vetorial (Pinecone)                    â”‚
â”‚  â€¢ Chunks semÃ¢nticos (LangChain)                      â”‚
â”‚  â€¢ Controle de contexto e histÃ³rico de consultas       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 Embedding & LLM Layer                 â”‚
â”‚  â€¢ HuggingFace Embeddings                             â”‚
â”‚  â€¢ LLM Modular (Groq, Gemini, Ollama, OpenAI, etc.)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     Ingest Layer                      â”‚
â”‚  â€¢ ExtraÃ§Ã£o de dados de PDFs, TXT e MD                â”‚
â”‚  â€¢ NormalizaÃ§Ã£o de documentos SUSEP/Open Finance      â”‚
â”‚  â€¢ TokenizaÃ§Ã£o e chunking regulatÃ³rio                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   Monitoring Layer                    â”‚
â”‚  â€¢ MÃ©tricas (Prometheus)                              â”‚
â”‚  â€¢ AvaliaÃ§Ã£o (RAGAs + MLflow)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## CaracterÃ­sticas Principais

### 1. Modularidade da IA

O agente nÃ£o estÃ¡ vinculado a uma IA especÃ­fica.
Ele opera sob um modelo de acoplamento dinÃ¢mico, aceitando qualquer provedor de modelo de linguagem (LLM) que possua API Key vÃ¡lida e suporte ao endpoint compatÃ­vel com o padrÃ£o OpenAI-like.

**Atualmente, sÃ£o suportados:**

- Groq API (mixtral, llama3, gemma2);

- Google Gemini (vÃ­a Vertex ou REST);

- OpenAI (gpt-4o, gpt-4-turbo);

- Ollama (modelos llama3, mistral, phi3);

Essa modularidade garante portabilidade, redundÃ¢ncia e independÃªncia tecnolÃ³gica, permitindo continuidade operacional mesmo diante de descontinuaÃ§Ãµes de modelos.

### 2. Base Regulamentar

**Os documentos utilizados sÃ£o fontes oficiais, pÃºblicas e auditÃ¡veis, incluindo:**

- Circulares, ResoluÃ§Ãµes e RDDs da SUSEP;

- Documentos tÃ©cnicos da OPIN (DiretÃ³rio de Participantes, CertificaÃ§Ã£o, GlossÃ¡rio, etc.);

- Manuais e guias publicados no Portal da SUSEP e no repositÃ³rio pÃºblico do Open Insurance Brasil.

Esses materiais sÃ£o armazenados localmente em */data/oi* e ingeridos via *scripts/ingest_local.py*.

### 3. IngestÃ£o e IndexaÃ§Ã£o

**A pipeline de ingestÃ£o realiza:**

- ExtraÃ§Ã£o e normalizaÃ§Ã£o de documentos (PyPDFLoader, UnstructuredMarkdownLoader);

- DivisÃ£o em blocos semÃ¢nticos (chunks) configurÃ¡veis via .env;

- CriaÃ§Ã£o e sincronizaÃ§Ã£o de embeddings (all-MiniLM-L6-v2) no Pinecone;

- Monitoramento de volume e latÃªncia para cada ciclo de ingestÃ£o.

O resultado Ã© um Ã­ndice vetorial consistente, capaz de responder a consultas com precisÃ£o contextual.

### 4. Consultas Inteligentes

As consultas podem ser realizadas via CLI:

```bash
python -m scripts.ask_oi "Quais sÃ£o os requisitos de certificados para clientes e servidores no Open Insurance Brasil?"
```
**O agente realiza:**

- RecuperaÃ§Ã£o dos 5 trechos mais relevantes (Top-K);

- ConsolidaÃ§Ã£o do contexto em prompt estruturado;

- GeraÃ§Ã£o de resposta fundamentada e rastreÃ¡vel, com metadados da fonte.

### 5. Base Conceitual e Pesquisa

**O projeto estÃ¡ ancorado em princÃ­pios acadÃªmicos e regulatÃ³rios sÃ³lidos:**

```bash
â€œA soluÃ§Ã£o proposta combina tÃ©cnicas de RAG e embeddings regulatÃ³rios com modelos de linguagem auditÃ¡veis, oferecendo um protÃ³tipo inovador para anÃ¡lise automatizada e segura de normas do Open Insurance Brasil.â€
```
**Essa estrutura visa:**

- Reduzir erros humanos em consultas normativas;

- Acelerar a conformidade regulatÃ³ria;

- Garantir rastreabilidade das respostas e explicabilidade algorÃ­tmica;

- Fortalecer a interoperabilidade entre Open Finance e Open Insurance;

- Apoiar a SUSEP e instituiÃ§Ãµes participantes na supervisÃ£o e implementaÃ§Ã£o de fases do Opin.

### 6. Riscos e Cuidados

- O sistema deve ser constantemente atualizado para refletir mudanÃ§as regulatÃ³rias.

- Ã‰ essencial manter mecanismos de auditoria e logging completo.

- As conexÃµes externas (Pinecone, LLM APIs) devem seguir padrÃµes de criptografia TLS 1.3.

*O uso institucional requer validaÃ§Ã£o prÃ©via da SUSEP e acompanhamento tÃ©cnico de conformidade.*

### 7. MÃ©tricas e Observabilidade

**O agente coleta mÃ©tricas em tempo real via Prometheus, permitindo monitorar:**

- LatÃªncia mÃ©dia de consulta;

- Taxa de acerto semÃ¢ntico (via RAGAs);

- Consumo de tokens e custo operacional;

- Disponibilidade e tempo de resposta das APIs conectadas.

Os experimentos sÃ£o versionados via MLflow e avaliados sob metodologia A/B com diferentes LLMs.

## ConfiguraÃ§Ã£o do Ambiente

### 1. PrÃ©-requisitos

Certifique-se de ter instalado:

- Python **3.10+**
- Git
- Virtualenv (recomendado)
- Conta ativa no [Pinecone](https://www.pinecone.io/)
- API Key vÃ¡lida para o provedor de LLM (Groq, Gemini, OpenAI, etc.)

---

### 2. Clonar o repositÃ³rio

```bash
git clone https://github.com/luciano-coelho/OpenInsuranceAgent.git
cd open-insurance-agent
```

### 3. Criar e ativar o ambiente virtual

```bash
python -m venv .venv
# Ativar o ambiente

# Windows
.venv\Scripts\activate

# Linux/Mac
source .venv/bin/activate
```

### 4. Instalar dependÃªncias

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### 5. Configurar variÃ¡veis de ambiente
Crie um arquivo .env na raiz do projeto com o seguinte conteÃºdo:

```bash
# ---- LLM / Embeddings ----
GROQ_API_KEY=your_groq_key
GEN_MODEL=llama3-8b-8192
EMBED_MODEL=all-MiniLM-L6-v2

# ---- Pinecone ----
PINECONE_API_KEY=your_pinecone_key
PINECONE_ENVIRONMENT=us-east-1
PINECONE_INDEX_NAME=open-insurance-index

# ---- RAG ----
TOP_K=5
CHUNK_SIZE=600
CHUNK_OVERLAP=80
```

âš ï¸ ObservaÃ§Ã£o:
O agente Ã© modular â€” ele nÃ£o estÃ¡ vinculado a uma IA especÃ­fica.
Basta trocar a chave e o nome do modelo no .env para usar Groq, Gemini, OpenAI, Ollama ou qualquer outro LLM compatÃ­vel com API REST no padrÃ£o OpenAI-like.

### 6. Adicionar os documentos oficiais
Coloque os arquivos normativos e tÃ©cnicos em:
```bash
/data/oi/
```

**Suporta os formatos:**

- .pdf
- .txt
- .md

**Exemplo:**
Circulares SUSEP, ResoluÃ§Ãµes CNSP, RDDs, perfis de seguranÃ§a do Open Finance, etc.

### 7. Executar a ingestÃ£o de documentos

```bash
python -m scripts.ingest_local
```

**Este comando irÃ¡:**

- Ler e processar os documentos;

- Gerar chunks semÃ¢nticos;

- Criar embeddings e enviar para o Pinecone.

### 8. Verificar o status do Ã­ndice

```bash
python -m scripts.check_pinecone
```
Exibe o total de vetores, status do Ã­ndice e amostra de metadados armazenados.

### 9. Realizar consultas

```bash
python -m scripts.ask_oi "Quais sÃ£o os requisitos de certificados para clientes e servidores no Open Insurance Brasil?"
```

---

## ğŸŒ API REST (Swagger/OpenAPI)

O sistema expÃµe uma **API REST completa** com documentaÃ§Ã£o interativa Swagger.

### Iniciar o servidor API

```powershell
python -m uvicorn main:app --reload --port 8000
```

Acesse a documentaÃ§Ã£o interativa: **http://127.0.0.1:8000/docs**

### Endpoints DisponÃ­veis

#### ğŸ“ POST `/api/v1/ask` - Consultar agente
Envia uma pergunta e recebe resposta fundamentada em documentos oficiais.

**Request Body:**
```json
{
  "question": "O que Ã© Open Insurance?",
  "prompt_style": "concise",
  "return_contexts": true
}
```

**Estilos de prompt:**
- `concise`: Respostas objetivas em 2-3 frases (padrÃ£o)
- `detailed`: ExplicaÃ§Ãµes detalhadas
- `bullet_points`: Respostas em tÃ³picos
- `yes_no`: Respostas binÃ¡rias com justificativa

**Response:**
```json
{
  "question": "O que Ã© Open Insurance?",
  "answer": "Open Insurance Ã© um sistema...",
  "model": "llama-3.3-70b-versatile",
  "provider": "groq",
  "latency_seconds": 2.34,
  "contexts": [...],
  "metadata": {...}
}
```

#### ğŸ¥ GET `/api/v1/health` - Health check
Verifica status da API e serviÃ§os.

**Response:**
```json
{
  "status": "healthy",
  "provider": "groq",
  "model": "llama-3.3-70b-versatile",
  "vectorstore_ready": true,
  "top_k": 7
}
```

#### ğŸ“Š GET `/api/v1/metrics` - MÃ©tricas do sistema
Retorna configuraÃ§Ãµes e parÃ¢metros do sistema.

**Response:**
```json
{
  "provider": "groq",
  "model": "llama-3.3-70b-versatile",
  "embedding_model": "sentence-transformers/all-MiniLM-L6-v2",
  "pinecone_index": "open-insurance-index",
  "top_k": 7,
  "chunk_size": 800,
  "use_mmr": true,
  "temperature": 0.3,
  "max_tokens": 300
}
```

### Exemplo de uso com cURL

```bash
# Consultar agente
curl -X POST "http://127.0.0.1:8000/api/v1/ask" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Quais sÃ£o os requisitos de certificados?",
    "prompt_style": "bullet_points",
    "return_contexts": false
  }'

# Health check
curl "http://127.0.0.1:8000/api/v1/health"

# MÃ©tricas
curl "http://127.0.0.1:8000/api/v1/metrics"
```

### ğŸ“¤ POST `/api/v1/upload` - Upload de documentos

Permite que a equipe faÃ§a upload de novos documentos oficiais. O sistema automaticamente:
1. Valida o arquivo (formato e tamanho)
2. Salva em `data/oi/`
3. Processa (chunking + embeddings)
4. Adiciona ao Ã­ndice Pinecone

**Formatos aceitos:** PDF, TXT, MD  
**Tamanho mÃ¡ximo:** 50 MB

**Exemplo com cURL:**
```bash
# Upload de arquivo
curl -X POST "http://127.0.0.1:8000/api/v1/upload" \
  -F "file=@circular_susep_123.pdf"
```

**Exemplo com Python:**
```python
import requests

# Upload de documento
with open("circular_susep_123.pdf", "rb") as f:
    response = requests.post(
        "http://127.0.0.1:8000/api/v1/upload",
        files={"file": f}
    )

result = response.json()
print(f"âœ… {result['message']}")
print(f"Chunks criados: {result['chunks_created']}")
print(f"Tempo: {result['processing_time_seconds']}s")
```

**Response:**
```json
{
  "success": true,
  "filename": "circular_susep_123.pdf",
  "file_path": "data/oi/circular_susep_123.pdf",
  "file_size_bytes": 2458624,
  "chunks_created": 45,
  "vectors_added": 45,
  "processing_time_seconds": 12.34,
  "message": "Documento 'circular_susep_123.pdf' processado e adicionado ao Ã­ndice Pinecone com sucesso!"
}
```

### Recursos da API

- âœ… **DocumentaÃ§Ã£o interativa** Swagger UI (`/docs`) e ReDoc (`/redoc`)
- âœ… **ValidaÃ§Ã£o automÃ¡tica** de requests com Pydantic
- âœ… **CORS habilitado** para integraÃ§Ã£o com frontends
- âœ… **Upload de documentos** com ingestÃ£o automÃ¡tica no Pinecone
- âœ… **MÃºltiplos estilos de prompt** (concise, detailed, bullet_points, yes_no)
- âœ… **Retorno opcional de contextos** recuperados do vectorstore
- âœ… **MÃ©tricas de latÃªncia** em todas as respostas
- âœ… **Health check** para monitoramento
- âœ… **Endpoints versionados** (`/api/v1/`)

---

###  Autores e Colaboradores

Luciano Coelho â€” Doutorando em CiÃªncia da ComputaÃ§Ã£o (UFSC / LabSEC)

Prof. Ricardo CustÃ³dio â€” Orientador (UFSC / LabSEC)

Manuel Matos â€” Coautor (CÃ¢mara e-net)

DrÂª. Patricia Figueiredo - SeleÃ§Ã£o de documentos normativos (Open Power Corretora de Seguros SA)